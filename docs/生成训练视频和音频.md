**ç»å¯¹ä¸èƒ½æ•´ä¸ªå¡ç»™TTSï¼** å¿…é¡»**é€è¡Œï¼ˆæˆ–é€æ®µï¼‰ç”Ÿæˆ**ï¼ŒåŸå› å¦‚ä¸‹ï¼š

## âŒ ä¸ºä»€ä¹ˆä¸èƒ½æ•´ä¸ªå¡è¿›å»ï¼Ÿ

1. **æƒ…ç»ªæ ‡æ³¨ä¼šæ··ä¹±**
   - æ–‡æ¡ˆä¸­æœ‰"å¼€å¿ƒ"ã€"æ‚²ä¼¤"ã€"ç”Ÿæ°”"ç­‰ä¸åŒæƒ…ç»ª
   - TTSéœ€è¦é’ˆå¯¹æ¯å¥è®¾ç½®å¯¹åº”æƒ…ç»ªå‚æ•°
   - æ•´æ®µè¾“å…¥ä¼šå¯¼è‡´æƒ…ç»ªä¸åŒ¹é…

2. **æ— æ³•åšéŸ³é¢‘-è§†é¢‘å¯¹é½**
   - è®­ç»ƒéœ€è¦ç²¾ç¡®çš„`{éŸ³é¢‘ç‰‡æ®µ â†’ è¿åŠ¨å‚æ•°}`å¯¹åº”å…³ç³»
   - æ•´æ®µç”Ÿæˆçš„éŸ³é¢‘æ— æ³•åˆ‡åˆ†å®šä½

3. **æ•°æ®æ ‡æ³¨å›°éš¾**
   - åç»­æå–è¿åŠ¨å‚æ•°æ—¶ï¼Œæ— æ³•çŸ¥é“å“ªæ®µéŸ³é¢‘å¯¹åº”å“ªä¸ªéŸ³ç´ 

---

## âœ… æ­£ç¡®ä½¿ç”¨æµç¨‹

### æ–¹æ¡ˆAï¼šPythonè„šæœ¬æ‰¹é‡ç”Ÿæˆï¼ˆæ¨èï¼‰---

## ğŸ“‹ å…·ä½“ä½¿ç”¨æ­¥éª¤

### æ­¥éª¤1ï¼šä¿®æ”¹è„šæœ¬é€‚é…ä½ çš„TTS

æ ¹æ®ä½ é€‰æ‹©çš„TTSæ¨¡å‹ï¼Œä¿®æ”¹`generate_audio`æ–¹æ³•ï¼š

#### å¦‚æœä½¿ç”¨ChatTTSï¼š
```python
from ChatTTS import ChatTTS

def __init__(self):
    # ...
    self.tts = ChatTTS.Chat()
    self.tts.load_models()

def generate_audio(self, text, emotion):
    # ChatTTSæ”¯æŒ[laugh]ã€[uv_break]ç­‰æ ‡è®°
    params = {
        'emotion': emotion,
        'speed': 1.0
    }
    audio = self.tts.infer(text, params_infer_code=params)
    return audio[0]  # è¿”å›numpy array
```

#### å¦‚æœä½¿ç”¨Kokoro TTSï¼š
```python
from kokoro import generate

def generate_audio(self, text, emotion):
    # Kokoroå¯èƒ½ä¸æ”¯æŒç›´æ¥æƒ…ç»ªæ§åˆ¶
    # éœ€è¦ç”¨è¯­æ°”è¯æˆ–è¯­é€Ÿæ¥æ¨¡æ‹Ÿ
    audio = generate(text, voice='af_sky', speed=1.0)
    return audio
```

#### å¦‚æœä½¿ç”¨CosyVoiceï¼š
```python
from cosyvoice import CosyVoice

def __init__(self):
    # ...
    self.tts = CosyVoice('pretrained_models/CosyVoice-300M')

def generate_audio(self, text, emotion):
    # CosyVoiceæ”¯æŒæƒ…ç»ªæ§åˆ¶
    emotion_map = {
        'neutral': 'å¹³é™',
        'happy': 'å¼€å¿ƒ',
        'sad': 'æ‚²ä¼¤',
        'angry': 'æ„¤æ€’',
        'surprised': 'æƒŠè®¶'
    }
    audio = self.tts.inference_instruct(
        text,
        instruct=f'{emotion_map[emotion]}åœ°è¯´'
    )
    return audio
```

---

### æ­¥éª¤2ï¼šè¿è¡Œç”Ÿæˆ

```bash
# å®‰è£…ä¾èµ–
pip install soundfile numpy

# è¿è¡Œè„šæœ¬
python tts_batch_generator.py
```

**è¾“å‡ºç›®å½•ç»“æ„ï¼š**
```
digital_human_training_data/
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ audio_0001.wav  # å¤§å®¶å¥½å•Šï¼ŒèŠ±èŠ±...
â”‚   â”œâ”€â”€ audio_0002.wav  # ä¸€ä¸ƒè¥¿ç“œ...
â”‚   â”œâ”€â”€ audio_0003.wav  # äº”è·¯ä¸å›¾ä¹¦...
â”‚   â””â”€â”€ ...
â””â”€â”€ metadata/
    â””â”€â”€ index.json      # æ‰€æœ‰éŸ³é¢‘çš„å…ƒæ•°æ®
```

**index.jsonå†…å®¹ç¤ºä¾‹ï¼š**
```json
[
  {
    "id": 1,
    "filename": "audio_0001.wav",
    "text": "å¤§å®¶å¥½å•Šï¼ŒèŠ±èŠ±ï¼Œçˆ¸çˆ¸å¦ˆå¦ˆï¼Œå“ˆå“ˆå¤§ç¬‘ã€‚",
    "section": "åŸºç¡€éŸ³ç´ -å•å…ƒéŸ³",
    "emotion": "neutral",
    "duration": 3.5
  },
  {
    "id": 2,
    "filename": "audio_0002.wav",
    "text": "ä¸€ä¸ƒè¥¿ç“œï¼Œæœºå™¨é¸¡é¸¡ï¼Œcheeseä¸€èµ·ã€‚",
    "section": "åŸºç¡€éŸ³ç´ -å•å…ƒéŸ³",
    "emotion": "neutral",
    "duration": 3.2
  }
]
```

---

### æ­¥éª¤3ï¼šç”Ÿæˆå¯¹åº”è§†é¢‘ï¼ˆä½¿ç”¨çœŸäººè§†é¢‘æˆ–JoyVASAï¼‰

#### æ–¹æ³•Aï¼šå¦‚æœä½¿ç”¨çœŸäººè§†é¢‘å½•åˆ¶

```python
# ä½ éœ€è¦è‡ªå·±å½•åˆ¶ä¸€ä¸ªè§†é¢‘ï¼Œè¯»å®Œæ•´æ–‡æ¡ˆ
# ç„¶åå¯¹é½éŸ³é¢‘å’Œè§†é¢‘
def align_audio_video(video_path, audio_metadata):
    """æ ¹æ®å…ƒæ•°æ®åˆ‡åˆ†è§†é¢‘"""
    import cv2
    from moviepy.editor import VideoFileClip

    video = VideoFileClip(video_path)

    for meta in audio_metadata:
        # æ ¹æ®æ—¶é—´æˆ³åˆ‡åˆ†
        start_time = meta['start_time']  # éœ€è¦æ‰‹åŠ¨æ ‡æ³¨æˆ–ç”¨è¯­éŸ³è¯†åˆ«å¯¹é½
        end_time = meta['end_time']

        clip = video.subclip(start_time, end_time)
        clip.write_videofile(f"video_{meta['id']:04d}.mp4")
```

#### æ–¹æ³•Bï¼šå¦‚æœä½¿ç”¨JoyVASA/LivePortraitç”Ÿæˆ

```python
from liveportrait import LivePortrait  # æˆ–JoyVASA

lp = LivePortrait()

def generate_videos_from_audio(audio_dir, source_image):
    """ä»éŸ³é¢‘ç”Ÿæˆè§†é¢‘"""
    for audio_file in audio_dir.glob("*.wav"):
        video = lp.generate(
            source_image=source_image,
            driving_audio=audio_file
        )
        video_path = audio_file.with_suffix('.mp4')
        save_video(video, video_path)
```

---

## ğŸ“Š æœ€ä½³å®è·µ

### 1. åˆ†æ‰¹ç”Ÿæˆï¼ŒåŠæ—¶æ£€æŸ¥

```python
# å…ˆç”Ÿæˆå‰10å¥æµ‹è¯•
test_sentences = script_sections[0]['sentences'][:10]
# æ£€æŸ¥éŸ³è´¨ã€æƒ…ç»ªã€æ—¶é•¿
# æ»¡æ„åå†æ‰¹é‡ç”Ÿæˆ
```

### 2. å¤šç‰ˆæœ¬ç”Ÿæˆï¼ˆæ•°æ®å¢å¼ºï¼‰

```python
# åŒä¸€å¥è¯ç”Ÿæˆ3ä¸ªç‰ˆæœ¬ï¼ˆä¸åŒè¯­é€Ÿï¼‰
for speed in [0.9, 1.0, 1.1]:
    audio = tts.generate(text, speed=speed)
    save_audio(audio, f"audio_{id}_speed{speed}.wav")
```

### 3. è´¨é‡æ£€æŸ¥

```python
def check_audio_quality(audio_path):
    """æ£€æŸ¥éŸ³é¢‘è´¨é‡"""
    import librosa

    audio, sr = librosa.load(audio_path)

    # æ£€æŸ¥æ—¶é•¿ï¼ˆå¤ªçŸ­æˆ–å¤ªé•¿éƒ½ä¸æ­£å¸¸ï¼‰
    duration = len(audio) / sr
    if duration < 0.5 or duration > 10:
        print(f"âš ï¸ æ—¶é•¿å¼‚å¸¸: {audio_path} ({duration}s)")

    # æ£€æŸ¥éŸ³é‡ï¼ˆå¤ªå°è¯´æ˜ç”Ÿæˆå¤±è´¥ï¼‰
    volume = np.abs(audio).mean()
    if volume < 0.01:
        print(f"âš ï¸ éŸ³é‡è¿‡ä½: {audio_path}")

    # æ£€æŸ¥æ˜¯å¦æœ‰é™éŸ³
    if np.all(audio == 0):
        print(f"âŒ å®Œå…¨é™éŸ³: {audio_path}")
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1ï¼šTTSç”Ÿæˆé€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ

**Aï¼šä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œ**
```python
from multiprocessing import Pool

def generate_one(args):
    text, emotion, output_path = args
    audio = tts.generate(text, emotion)
    save_audio(audio, output_path)

# 8è¿›ç¨‹å¹¶è¡Œ
with Pool(8) as p:
    p.map(generate_one, task_list)
```

### Q2ï¼šä¸åŒTTSæ¨¡å‹æƒ…ç»ªæ•ˆæœå·®å¼‚å¤§ï¼Ÿ

**Aï¼šç»Ÿä¸€åå¤„ç†**
```python
def normalize_emotion(audio, target_emotion):
    """ç”¨éŸ³é¢‘å¤„ç†åº“è°ƒæ•´æƒ…ç»ªç‰¹å¾"""
    if target_emotion == 'happy':
        # æé«˜éŸ³è°ƒ
        audio = librosa.effects.pitch_shift(audio, sr=22050, n_steps=2)
    elif target_emotion == 'sad':
        # é™ä½éŸ³è°ƒ
        audio = librosa.effects.pitch_shift(audio, sr=22050, n_steps=-2)
    return audio
```

### Q3ï¼šå¦‚ä½•ç¡®ä¿éŸ³é¢‘å’Œè§†é¢‘å®Œç¾å¯¹é½ï¼Ÿ

**Aï¼šä½¿ç”¨æ—¶é—´æˆ³è®°å½•**
```python
# åœ¨ç”Ÿæˆæ—¶è®°å½•ç²¾ç¡®æ—¶é—´æˆ³
metadata = {
    "audio_file": "audio_0001.wav",
    "video_file": "video_0001.mp4",
    "start_frame": 0,
    "end_frame": 75,  # å‡è®¾25fpsï¼Œ3ç§’=75å¸§
    "alignment_offset": 0.05  # å¦‚æœæœ‰å»¶è¿Ÿï¼Œè®°å½•åç§»
}
```

---

## ğŸ¯ æ€»ç»“

**æ­£ç¡®æµç¨‹ï¼š**
```
1. é€è¡Œ/é€æ®µç”ŸæˆéŸ³é¢‘ â†’ ä¿å­˜ä¸ºç‹¬ç«‹æ–‡ä»¶
2. è®°å½•å…ƒæ•°æ®ï¼ˆæ–‡æœ¬ã€æƒ…ç»ªã€æ—¶é•¿ï¼‰â†’ ä¿å­˜ä¸ºJSON
3. åç»­è®­ç»ƒæ—¶ï¼Œæ ¹æ®å…ƒæ•°æ®åŠ è½½å¯¹åº”çš„éŸ³é¢‘-è§†é¢‘å¯¹
```

**é”™è¯¯æµç¨‹ï¼š**
```
âŒ æ•´æ®µæ–‡æœ¬ â†’ ä¸€ä¸ªé•¿éŸ³é¢‘ â†’ æ— æ³•æ ‡æ³¨ â†’ è®­ç»ƒå¤±è´¥
```

ä½¿ç”¨æˆ‘æä¾›çš„è„šæœ¬ï¼Œå¯ä»¥ï¼š
- âœ… è‡ªåŠ¨é€å¥ç”Ÿæˆ
- âœ… ä¿å­˜å®Œæ•´å…ƒæ•°æ®
- âœ… æ”¯æŒå¤šç§TTS
- âœ… ä¾¿äºåç»­æ•°æ®å¯¹é½

éœ€è¦æˆ‘å¸®ä½ é€‚é…ç‰¹å®šçš„TTSæ¨¡å‹å—ï¼Ÿæˆ–è€…è§£ç­”å…¶ä»–æ•°æ®å‡†å¤‡é—®é¢˜ï¼Ÿ
