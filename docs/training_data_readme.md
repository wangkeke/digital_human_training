# æ•°å­—äººè®­ç»ƒæ•°æ®ç”Ÿæˆä½¿ç”¨æŒ‡å—

## ğŸ“¦ æ–‡ä»¶è¯´æ˜

1. **training_script.json** - å®Œæ•´è®­ç»ƒæ–‡æ¡ˆæ•°æ®
2. **tts_batch_generator.py** - TTSæ‰¹é‡ç”Ÿæˆè„šæœ¬

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ­¥éª¤1ï¼šå‡†å¤‡ç¯å¢ƒ

```bash
# åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir digital_human_training
cd digital_human_training

# å®‰è£…ä¾èµ–
pip install soundfile numpy

# æ ¹æ®ä½ é€‰æ‹©çš„TTSå®‰è£…å¯¹åº”çš„åº“
# ChatTTS
pip install ChatTTS

# æˆ– Kokoro
pip install kokoro-tts

# æˆ– CosyVoice
pip install cosyvoice
```

### æ­¥éª¤2ï¼šå‡†å¤‡æ–‡ä»¶

```bash
# å°†ä¸¤ä¸ªartifactä¿å­˜ä¸ºæ–‡ä»¶
# 1. å¤åˆ¶ "å®Œæ•´è®­ç»ƒæ–‡æ¡ˆJSONæ•°æ®" ä¿å­˜ä¸º training_script.json
# 2. å¤åˆ¶ "TTSæ‰¹é‡ç”Ÿæˆè„šæœ¬" ä¿å­˜ä¸º tts_batch_generator.py

# ç›®å½•ç»“æ„åº”è¯¥æ˜¯ï¼š
digital_human_training/
â”œâ”€â”€ training_script.json
â””â”€â”€ tts_batch_generator.py
```

### æ­¥éª¤3ï¼šé…ç½®TTSæ¨¡å‹

ç¼–è¾‘ `tts_batch_generator.py`ï¼Œæ ¹æ®ä½ çš„TTSä¿®æ”¹ä»¥ä¸‹éƒ¨åˆ†ï¼š

#### å¦‚æœä½¿ç”¨ ChatTTSï¼ˆæ¨èï¼‰

```python
from ChatTTS import ChatTTS

class TrainingDataGenerator:
    def __init__(self, output_dir="training_data"):
        # ... å…¶ä»–ä»£ç  ...

        # åˆå§‹åŒ–ChatTTS
        self.tts = ChatTTS.Chat()
        self.tts.load_models()

    def generate_audio(self, text: str, emotion: str = "neutral"):
        # æƒ…ç»ªæ˜ å°„
        emotion_params = {
            'neutral': {'temperature': 0.3},
            'happy': {'temperature': 0.5, 'top_p': 0.7},
            'sad': {'temperature': 0.2, 'top_p': 0.8},
            'angry': {'temperature': 0.6, 'top_p': 0.6},
            'surprised': {'temperature': 0.5, 'top_p': 0.7}
        }

        params = emotion_params.get(emotion, emotion_params['neutral'])

        # ç”ŸæˆéŸ³é¢‘
        wavs = self.tts.infer(
            text,
            params_infer_code=params,
            use_decoder=True
        )

        # è¿”å›numpy array
        return wavs[0]
```

#### å¦‚æœä½¿ç”¨ Kokoro

```python
from kokoro import generate

class TrainingDataGenerator:
    def __init__(self, output_dir="training_data"):
        # ... å…¶ä»–ä»£ç  ...
        # Kokoroä¸éœ€è¦åˆå§‹åŒ–
        pass

    def generate_audio(self, text: str, emotion: str = "neutral"):
        # Kokoroé€šè¿‡è¯­é€Ÿå’ŒéŸ³è°ƒæ¨¡æ‹Ÿæƒ…ç»ª
        speed_map = {
            'neutral': 1.0,
            'happy': 1.1,
            'sad': 0.9,
            'angry': 1.05,
            'surprised': 1.15
        }

        speed = speed_map.get(emotion, 1.0)

        # ç”ŸæˆéŸ³é¢‘
        audio = generate(
            text,
            voice='af_sky',  # æˆ–å…¶ä»–å¯ç”¨å£°éŸ³
            speed=speed
        )

        return audio
```

#### å¦‚æœä½¿ç”¨ CosyVoice

```python
from cosyvoice.cli.cosyvoice import CosyVoice

class TrainingDataGenerator:
    def __init__(self, output_dir="training_data"):
        # ... å…¶ä»–ä»£ç  ...

        # åˆå§‹åŒ–CosyVoice
        self.tts = CosyVoice('pretrained_models/CosyVoice-300M')

    def generate_audio(self, text: str, emotion: str = "neutral"):
        # æƒ…ç»ªæè¿°
        emotion_instruct = {
            'neutral': 'å¹³é™åœ°è¯´',
            'happy': 'å¼€å¿ƒåœ°è¯´',
            'sad': 'æ‚²ä¼¤åœ°è¯´',
            'angry': 'æ„¤æ€’åœ°è¯´',
            'surprised': 'æƒŠè®¶åœ°è¯´',
            'thoughtful': 'æ€è€ƒç€è¯´',
            'fearful': 'å®³æ€•åœ°è¯´',
            'tired': 'ç–²æƒ«åœ°è¯´',
            'gentle': 'æ¸©æŸ”åœ°è¯´',
            'confident': 'è‡ªä¿¡åœ°è¯´',
            'professional': 'ä¸“ä¸šåœ°è¯´',
            'casual': 'éšæ„åœ°è¯´',
            'curious': 'å¥½å¥‡åœ°é—®',
            'storytelling': 'è®²æ•…äº‹èˆ¬è¯´'
        }

        instruct = emotion_instruct.get(emotion, 'å¹³é™åœ°è¯´')

        # ç”ŸæˆéŸ³é¢‘
        output = self.tts.inference_instruct(
            text,
            sft_dropdown='ä¸­æ–‡å¥³',
            instruct_text=instruct
        )

        # æå–éŸ³é¢‘æ•°æ®
        audio = output['tts_speech'].numpy()
        return audio
```

### æ­¥éª¤4ï¼šè¿è¡Œç”Ÿæˆ

```bash
python tts_batch_generator.py
```

### æ­¥éª¤5ï¼šæŸ¥çœ‹ç»“æœ

ç”Ÿæˆå®Œæˆåï¼Œç›®å½•ç»“æ„ï¼š

```
digital_human_training/
â”œâ”€â”€ training_script.json
â”œâ”€â”€ tts_batch_generator.py
â””â”€â”€ digital_human_training_data/
    â”œâ”€â”€ audio/
    â”‚   â”œâ”€â”€ audio_0001.wav  # å¤§å®¶å¥½å•Šï¼ŒèŠ±èŠ±...
    â”‚   â”œâ”€â”€ audio_0002.wav  # ä¸€ä¸ƒè¥¿ç“œ...
    â”‚   â”œâ”€â”€ audio_0003.wav  # äº”è·¯ä¸å›¾ä¹¦...
    â”‚   â””â”€â”€ ... (çº¦80+ä¸ªæ–‡ä»¶)
    â””â”€â”€ metadata/
        â””â”€â”€ index.json      # æ‰€æœ‰éŸ³é¢‘çš„ç´¢å¼•
```

## ğŸ“Š æ•°æ®ç»Ÿè®¡

å®Œæ•´æ–‡æ¡ˆåŒ…å«ï¼š
- **43ä¸ªsection**ï¼ˆéŸ³ç´ å’Œåœºæ™¯åˆ†ç±»ï¼‰
- **çº¦85-90å¥è¯**ï¼ˆå–å†³äºå¥å­æ‹†åˆ†ï¼‰
- **æ€»æ—¶é•¿**ï¼šçº¦20-30åˆ†é’ŸéŸ³é¢‘
- **è¦†ç›–å†…å®¹**ï¼š
  - âœ… 21ä¸ªä¸­æ–‡å£°æ¯
  - âœ… 39ä¸ªéŸµæ¯
  - âœ… å››å£°è°ƒ
  - âœ… 10ç§æƒ…ç»ª
  - âœ… è‹±æ–‡åŸºç¡€éŸ³ç´ 

## ğŸ”§ é«˜çº§é…ç½®

### 1. è‡ªå®šä¹‰æ–‡æ¡ˆ

å¦‚æœä½ æƒ³æ·»åŠ è‡ªå·±çš„å¥å­ï¼Œç¼–è¾‘ `training_script.json`ï¼š

```json
[
  {
    "section": "è‡ªå®šä¹‰åœºæ™¯-é—®å€™è¯­",
    "emotion": "happy",
    "sentences": [
      "ä½ å¥½ï¼Œæ¬¢è¿å…‰ä¸´ï¼",
      "å¾ˆé«˜å…´è§åˆ°ä½ ï¼"
    ]
  }
]
```

### 2. å¤šç‰ˆæœ¬ç”Ÿæˆï¼ˆæ•°æ®å¢å¼ºï¼‰

ä¿®æ”¹ `generate_training_set()` æ–¹æ³•ï¼š

```python
# åŒä¸€å¥è¯ç”Ÿæˆå¤šä¸ªç‰ˆæœ¬
for sentence in section['sentences']:
    for speed in [0.9, 1.0, 1.1]:  # ä¸‰ç§è¯­é€Ÿ
        audio_data = self.generate_audio(
            text=sentence,
            emotion=section['emotion'],
            speed=speed  # éœ€è¦TTSæ”¯æŒ
        )

        audio_filename = f"audio_{audio_id:04d}_speed{speed}.wav"
        self.save_audio(audio_data, audio_path)
```

### 3. æ‰¹é‡å¹¶è¡Œç”Ÿæˆ

```python
from multiprocessing import Pool

def generate_one_audio(args):
    text, emotion, output_path = args
    # ... ç”Ÿæˆé€»è¾‘

# åœ¨ generate_training_set() ä¸­ï¼š
tasks = []
for section in script_sections:
    for sentence in section['sentences']:
        tasks.append((sentence, section['emotion'], output_path))

# 8è¿›ç¨‹å¹¶è¡Œ
with Pool(8) as pool:
    pool.map(generate_one_audio, tasks)
```

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: ç”Ÿæˆçš„éŸ³é¢‘è´¨é‡ä¸å¥½ï¼Ÿ

**A:** æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. TTSæ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½
2. æƒ…ç»ªå‚æ•°æ˜¯å¦è®¾ç½®åˆç†
3. é‡‡æ ·ç‡æ˜¯å¦ä¸€è‡´ï¼ˆå»ºè®®22050æˆ–24000ï¼‰
4. éŸ³é¢‘æ˜¯å¦æœ‰å™ªéŸ³ï¼ˆæ£€æŸ¥é™å™ªè®¾ç½®ï¼‰

### Q2: æŸäº›æƒ…ç»ªæ•ˆæœä¸æ˜æ˜¾ï¼Ÿ

**A:**
1. ä¸åŒTTSå¯¹æƒ…ç»ªæ”¯æŒä¸åŒï¼ŒChatTTSå’ŒCosyVoiceæ•ˆæœè¾ƒå¥½
2. å¯ä»¥æ‰‹åŠ¨è°ƒæ•´æƒ…ç»ªå‚æ•°ï¼ˆtemperature, top_pç­‰ï¼‰
3. æˆ–è€…åæœŸç”¨éŸ³é¢‘å¤„ç†è°ƒæ•´ï¼ˆpitch shiftç­‰ï¼‰

### Q3: ç”Ÿæˆé€Ÿåº¦å¤ªæ…¢ï¼Ÿ

**A:**
1. ä½¿ç”¨GPUåŠ é€Ÿï¼ˆå¦‚æœTTSæ”¯æŒï¼‰
2. ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œç”Ÿæˆ
3. å…ˆç”Ÿæˆä¸€å°éƒ¨åˆ†æµ‹è¯•ï¼Œç¡®è®¤æ— è¯¯åå†æ‰¹é‡ç”Ÿæˆ

### Q4: å¦‚ä½•éªŒè¯ç”Ÿæˆçš„éŸ³é¢‘æ˜¯å¦æ­£ç¡®ï¼Ÿ

**A:** æ·»åŠ è´¨é‡æ£€æŸ¥ä»£ç ï¼š

```python
def check_audio_quality(audio_path):
    import librosa
    audio, sr = librosa.load(audio_path)

    # æ£€æŸ¥æ—¶é•¿
    duration = len(audio) / sr
    if duration < 0.5 or duration > 10:
        print(f"âš ï¸ æ—¶é•¿å¼‚å¸¸: {audio_path}")

    # æ£€æŸ¥éŸ³é‡
    volume = np.abs(audio).mean()
    if volume < 0.01:
        print(f"âš ï¸ éŸ³é‡è¿‡ä½: {audio_path}")

    return duration, volume

# åœ¨ç”Ÿæˆåè°ƒç”¨
for meta in all_metadata:
    check_audio_quality(meta['filename'])
```

## ğŸ“ ä¸‹ä¸€æ­¥ï¼šç”Ÿæˆè®­ç»ƒè§†é¢‘

ç”ŸæˆéŸ³é¢‘åï¼Œéœ€è¦é…åˆè§†é¢‘ç”Ÿæˆè¿åŠ¨å‚æ•°ï¼š

1. **æ–¹æ³•A - çœŸäººè§†é¢‘å½•åˆ¶**
   - æ‰¾ä¸€ä¸ªäººæŒ‰é¡ºåºè¯»å®Œæ‰€æœ‰å¥å­
   - ç”¨LivePortraitæå–è¿åŠ¨å‚æ•°

2. **æ–¹æ³•B - AIç”Ÿæˆè§†é¢‘**
   - ä½¿ç”¨JoyVASAä»éŸ³é¢‘ç”Ÿæˆè§†é¢‘
   - ç”¨LivePortraitæå–è¿åŠ¨å‚æ•°

3. **æ–¹æ³•C - ä½¿ç”¨ç°æˆæ•°æ®é›†**
   - MEADæ•°æ®é›†ï¼ˆå¤šæƒ…ç»ªï¼‰
   - VoxCelebæ•°æ®é›†

è¯¦è§åç»­æ•™ç¨‹ï¼šã€ŠAudio2Motionæ¨¡å‹è®­ç»ƒæŒ‡å—ã€‹

## ğŸ“š ç›¸å…³èµ„æº

- [LivePortraitå®˜æ–¹ä»“åº“](https://github.com/KwaiVGI/LivePortrait)
- [ChatTTSæ–‡æ¡£](https://github.com/2noise/ChatTTS)
- [CosyVoiceæ–‡æ¡£](https://github.com/FunAudioLLM/CosyVoice)
- [æ•°å­—äººå®Œæ•´è®­ç»ƒæµç¨‹](é“¾æ¥åˆ°ä½ çš„æ–‡æ¡£)

## ğŸ’¡ æç¤º

- å»ºè®®å…ˆç”¨10å¥è¯æµ‹è¯•å®Œæ•´æµç¨‹
- ç¡®è®¤éŸ³è´¨ã€æƒ…ç»ªã€æ—¶é•¿éƒ½ç¬¦åˆé¢„æœŸ
- å†æ‰¹é‡ç”Ÿæˆå…¨éƒ¨æ•°æ®
- ä¿ç•™åŸå§‹éŸ³é¢‘ï¼ˆä¸è¦å‹ç¼©ï¼‰ï¼Œåç»­è®­ç»ƒæ—¶å¯èƒ½éœ€è¦é‡æ–°å¤„ç†
