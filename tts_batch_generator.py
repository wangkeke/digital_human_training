"""
æ•°å­—äººè®­ç»ƒæ•°æ®ç”Ÿæˆå™¨ - CosyVoice3ç‰ˆæœ¬ï¼ˆä¿®æ­£ç‰ˆï¼‰
ä½¿ç”¨é˜¿é‡Œå¼€æºçš„ Fun-CosyVoice3-0.5B æ‰¹é‡ç”ŸæˆéŸ³é¢‘

ä½¿ç”¨æ–¹æ³•:
1. å…‹éš†CosyVoiceä»“åº“: git clone https://github.com/FunAudioLLM/CosyVoice.git
2. å®‰è£…ä¾èµ–: cd CosyVoice && pip install -r requirements.txt
3. å°†æ­¤è„šæœ¬æ”¾åœ¨ CosyVoice ç›®å½•ä¸‹
4. å‡†å¤‡å‚è€ƒéŸ³é¢‘: ./asset/zero_shot_prompt.wav (æˆ–è‡ªå·±çš„å‚è€ƒéŸ³é¢‘)
5. è¿è¡Œ: python tts_batch_generator.py

æ¨¡å¼é€‰æ‹©:
- instruct2 (æ¨è): é€šè¿‡æŒ‡ä»¤æ§åˆ¶æƒ…ç»ªã€è¯­é€Ÿ
- zero_shot: çº¯éŸ³è‰²å…‹éš†
"""

import sys
import json
import os
from pathlib import Path
from typing import List, Dict

# æ·»åŠ CosyVoiceè·¯å¾„
sys.path.append('third_party/Matcha-TTS')

from cosyvoice.cli.cosyvoice import AutoModel
import torchaudio


class CosyVoice3Generator:
    def __init__(self,
                 output_dir="training_data",
                 model_dir='pretrained_models/Fun-CosyVoice3-0.5B',
                 prompt_audio='./asset/zero_shot_prompt.wav',
                 mode='instruct2'):
        """
        åˆå§‹åŒ–CosyVoice3ç”Ÿæˆå™¨

        Args:
            output_dir: è¾“å‡ºç›®å½•
            model_dir: æ¨¡å‹è·¯å¾„ï¼ˆä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
            prompt_audio: å‚è€ƒéŸ³é¢‘è·¯å¾„ï¼ˆ"å°O"çš„éŸ³é¢‘æ ·æœ¬ï¼‰
            mode: ç”Ÿæˆæ¨¡å¼ ('instruct2' æˆ– 'zero_shot')
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

        # åˆ›å»ºå­ç›®å½•
        (self.output_dir / "audio").mkdir(exist_ok=True)
        (self.output_dir / "metadata").mkdir(exist_ok=True)

        self.prompt_audio = prompt_audio
        self.mode = mode

        # æ£€æŸ¥å‚è€ƒéŸ³é¢‘æ˜¯å¦å­˜åœ¨
        if not os.path.exists(prompt_audio):
            print(f"\nâš ï¸  è­¦å‘Š: å‚è€ƒéŸ³é¢‘ä¸å­˜åœ¨: {prompt_audio}")
            print("è¯·å‡†å¤‡ä¸€æ®µ'å°O'çš„éŸ³é¢‘æ ·æœ¬ï¼ˆ10-30ç§’ï¼‰ï¼Œä¿å­˜ä¸º:")
            print(f"  {prompt_audio}")
            print("\nå¦‚æœä½¿ç”¨é»˜è®¤å‚è€ƒéŸ³é¢‘ï¼Œè¯·ç¡®ä¿:")
            print("  ./asset/zero_shot_prompt.wav å­˜åœ¨")
            raise FileNotFoundError(f"å‚è€ƒéŸ³é¢‘ä¸å­˜åœ¨: {prompt_audio}")

        # åˆå§‹åŒ–æ¨¡å‹
        print(f"\næ­£åœ¨åŠ è½½ CosyVoice3 æ¨¡å‹...")
        print(f"æ¨¡å‹è·¯å¾„: {model_dir}")
        print(f"å¦‚æœæ˜¯é¦–æ¬¡è¿è¡Œï¼Œå°†è‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼ˆçº¦500MBï¼‰")

        try:
            self.cosyvoice = AutoModel(model_dir=model_dir)
            self.sample_rate = self.cosyvoice.sample_rate

            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼é‡‡æ ·ç‡: {self.sample_rate}Hz")
            print(f"âœ… ä½¿ç”¨æ¨¡å¼: {mode}")
            print(f"âœ… å‚è€ƒéŸ³é¢‘: {prompt_audio}")
        except Exception as e:
            print(f"\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("\nè¯·ç¡®ä¿:")
            print("  1. å·²å…‹éš†CosyVoiceä»“åº“")
            print("  2. å·²å®‰è£…æ‰€æœ‰ä¾èµ–: pip install -r requirements.txt")
            print("  3. åœ¨CosyVoiceç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
            raise

        # æƒ…ç»ªæ˜ å°„åˆ°æŒ‡ä»¤
        self.emotion_to_instruct = {
            'neutral': 'è¯·ç”¨å¹³é™è‡ªç„¶çš„è¯­æ°”è¯´è¯ã€‚',
            'happy': 'è¯·ç”¨å¼€å¿ƒã€æ„‰å¿«ã€å…´å¥‹çš„è¯­æ°”è¯´è¯ã€‚',
            'sad': 'è¯·ç”¨æ‚²ä¼¤ã€ä½è½ã€éš¾è¿‡çš„è¯­æ°”è¯´è¯ã€‚',
            'angry': 'è¯·ç”¨æ„¤æ€’ã€ç”Ÿæ°”ã€æ¿€åŠ¨çš„è¯­æ°”è¯´è¯ã€‚',
            'surprised': 'è¯·ç”¨æƒŠè®¶ã€åƒæƒŠã€ä¸å¯æ€è®®çš„è¯­æ°”è¯´è¯ã€‚',
            'thoughtful': 'è¯·ç”¨æ€è€ƒã€æ²‰æ€ã€çŠ¹è±«çš„è¯­æ°”è¯´è¯ã€‚',
            'fearful': 'è¯·ç”¨å®³æ€•ã€ç´§å¼ ã€æ‹…å¿ƒçš„è¯­æ°”è¯´è¯ã€‚',
            'tired': 'è¯·ç”¨ç–²æƒ«ã€æ— å¥ˆã€æ‡’æ•£çš„è¯­æ°”è¯´è¯ã€‚',
            'gentle': 'è¯·ç”¨æ¸©æŸ”ã€æŸ”å’Œã€è½»å£°ç»†è¯­çš„è¯­æ°”è¯´è¯ã€‚',
            'confident': 'è¯·ç”¨è‡ªä¿¡ã€åšå®šã€æœ‰åŠ›çš„è¯­æ°”è¯´è¯ã€‚',
            'professional': 'è¯·ç”¨ä¸“ä¸šã€æ­£å¼ã€ä¸¥è‚ƒçš„è¯­æ°”è¯´è¯ã€‚',
            'casual': 'è¯·ç”¨éšæ„ã€è½»æ¾ã€èŠå¤©çš„è¯­æ°”è¯´è¯ã€‚',
            'curious': 'è¯·ç”¨å¥½å¥‡ã€ç–‘é—®ã€è¯¢é—®çš„è¯­æ°”è¯´è¯ã€‚',
            'storytelling': 'è¯·ç”¨è®²æ•…äº‹èˆ¬ç”ŸåŠ¨ã€æœ‰è¶£ã€æŠ“äººçš„è¯­æ°”è¯´è¯ã€‚'
        }

    def generate_training_set(self, script_json_path="training_script.json"):
        """ç”Ÿæˆå®Œæ•´è®­ç»ƒé›†"""

        # ä»JSONæ–‡ä»¶åŠ è½½æ–‡æ¡ˆ
        with open(script_json_path, 'r', encoding='utf-8') as f:
            script_sections = json.load(f)

        # ç”ŸæˆéŸ³é¢‘
        all_metadata = []
        audio_id = 0

        print(f"\nå¼€å§‹ç”ŸæˆéŸ³é¢‘...")
        print(f"æ€»sectionæ•°: {len(script_sections)}")
        print(f"é¢„è®¡ç”Ÿæˆå¥å­æ•°: {sum(len(s['sentences']) for s in script_sections)}")

        for section_idx, section in enumerate(script_sections, 1):
            print(f"\n{'='*60}")
            print(f"[{section_idx}/{len(script_sections)}] {section['section']}")
            print(f"{'='*60}")

            for sentence_idx, sentence in enumerate(section['sentences'], 1):
                audio_id += 1

                # ç”ŸæˆéŸ³é¢‘æ–‡ä»¶å
                audio_filename = f"audio_{audio_id:04d}.wav"
                audio_path = self.output_dir / "audio" / audio_filename

                # æ˜¾ç¤ºè¿›åº¦
                print(f"  [{sentence_idx}/{len(section['sentences'])}] æ­£åœ¨ç”Ÿæˆ...")
                print(f"  æ–‡æœ¬: {sentence[:50]}{'...' if len(sentence) > 50 else ''}")
                print(f"  æƒ…ç»ª: {section['emotion']}")

                try:
                    # ç”ŸæˆéŸ³é¢‘
                    audio_tensor = self.generate_audio(
                        text=sentence,
                        emotion=section['emotion']
                    )

                    # ä¿å­˜éŸ³é¢‘
                    torchaudio.save(str(audio_path), audio_tensor, self.sample_rate)

                    # è®¡ç®—æ—¶é•¿
                    duration = audio_tensor.shape[1] / self.sample_rate

                    print(f"  âœ… æˆåŠŸ: {audio_filename} ({duration:.2f}s)")

                    # è®°å½•å…ƒæ•°æ®
                    metadata = {
                        "id": audio_id,
                        "filename": audio_filename,
                        "text": sentence,
                        "section": section['section'],
                        "emotion": section['emotion'],
                        "duration": round(duration, 2),
                        "sample_rate": self.sample_rate
                    }
                    all_metadata.append(metadata)

                except Exception as e:
                    print(f"  âŒ ç”Ÿæˆå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    continue

        # ä¿å­˜å…ƒæ•°æ®ç´¢å¼•
        metadata_path = self.output_dir / "metadata" / "index.json"
        with open(metadata_path, "w", encoding="utf-8") as f:
            json.dump(all_metadata, f, ensure_ascii=False, indent=2)

        # ç»Ÿè®¡ä¿¡æ¯
        total_duration = sum(m['duration'] for m in all_metadata)

        print(f"\n{'='*60}")
        print(f"âœ… å®Œæˆï¼")
        print(f"{'='*60}")
        print(f"æˆåŠŸç”Ÿæˆ: {len(all_metadata)} ä¸ªéŸ³é¢‘")
        print(f"å¤±è´¥æ•°é‡: {audio_id - len(all_metadata)}")
        print(f"æ€»æ—¶é•¿: {total_duration/60:.1f} åˆ†é’Ÿ")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"å…ƒæ•°æ®: {metadata_path}")

        return all_metadata

    def generate_audio(self, text: str, emotion: str = "neutral"):
        """
        ä½¿ç”¨CosyVoice3ç”Ÿæˆå•å¥éŸ³é¢‘

        Args:
            text: è¦ç”Ÿæˆçš„æ–‡æœ¬
            emotion: æƒ…ç»ªæ ‡ç­¾

        Returns:
            audio_tensor: torch.Tensor, shape (1, samples)
        """
        # æ„å»ºæŒ‡ä»¤
        instruct = self.emotion_to_instruct.get(emotion, self.emotion_to_instruct['neutral'])
        prompt_text = f"You are a helpful assistant. {instruct}<|endofprompt|>"

        if self.mode == 'instruct2':
            # ä½¿ç”¨instruct2æ¨¡å¼ï¼ˆæ¨èï¼‰
            # æ ¹æ®å®˜æ–¹ç¤ºä¾‹: inference_instruct2(text, prompt_text, prompt_audio, stream=False)
            output = None
            for i, j in enumerate(self.cosyvoice.inference_instruct2(
                text,
                prompt_text,
                self.prompt_audio,
                stream=False
            )):
                output = j['tts_speech']
                break  # åªå–ç¬¬ä¸€ä¸ªè¾“å‡º

            if output is None:
                raise RuntimeError("ç”Ÿæˆå¤±è´¥ï¼šæœªè¿”å›éŸ³é¢‘æ•°æ®")

            return output

        elif self.mode == 'zero_shot':
            # ä½¿ç”¨zero_shotæ¨¡å¼
            # æ ¹æ®å®˜æ–¹ç¤ºä¾‹: inference_zero_shot(text, prompt_text, prompt_audio, stream=False)
            output = None
            for i, j in enumerate(self.cosyvoice.inference_zero_shot(
                text,
                prompt_text,
                self.prompt_audio,
                stream=False
            )):
                output = j['tts_speech']
                break

            if output is None:
                raise RuntimeError("ç”Ÿæˆå¤±è´¥ï¼šæœªè¿”å›éŸ³é¢‘æ•°æ®")

            return output

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å¼: {self.mode}ï¼Œè¯·ä½¿ç”¨ 'instruct2' æˆ– 'zero_shot'")


def test_cosyvoice_setup():
    """æµ‹è¯•CosyVoiceç¯å¢ƒæ˜¯å¦æ­£ç¡®é…ç½®"""
    print("\n" + "="*60)
    print("æµ‹è¯•CosyVoiceç¯å¢ƒ")
    print("="*60)

    try:
        # æµ‹è¯•å¯¼å…¥
        print("\n1. æµ‹è¯•å¯¼å…¥...")
        from cosyvoice.cli.cosyvoice import AutoModel
        print("   âœ… å¯¼å…¥æˆåŠŸ")

        # æµ‹è¯•æ¨¡å‹åŠ è½½
        print("\n2. æµ‹è¯•æ¨¡å‹åŠ è½½...")
        model_dir = 'pretrained_models/Fun-CosyVoice3-0.5B'
        if not os.path.exists(model_dir):
            print(f"   âš ï¸  æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}")
            print("   å°†åœ¨é¦–æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½")
        else:
            print(f"   âœ… æ¨¡å‹ç›®å½•å­˜åœ¨: {model_dir}")

        # æµ‹è¯•å‚è€ƒéŸ³é¢‘
        print("\n3. æµ‹è¯•å‚è€ƒéŸ³é¢‘...")
        prompt_audio = './asset/zero_shot_prompt.wav'
        if os.path.exists(prompt_audio):
            print(f"   âœ… å‚è€ƒéŸ³é¢‘å­˜åœ¨: {prompt_audio}")
        else:
            print(f"   âš ï¸  å‚è€ƒéŸ³é¢‘ä¸å­˜åœ¨: {prompt_audio}")
            print("   è¯·å‡†å¤‡å‚è€ƒéŸ³é¢‘æˆ–ä½¿ç”¨è‡ªå·±çš„éŸ³é¢‘")

        print("\n" + "="*60)
        print("ç¯å¢ƒæ£€æŸ¥å®Œæˆï¼å¯ä»¥å¼€å§‹ç”Ÿæˆ")
        print("="*60)

        return True

    except Exception as e:
        print(f"\nâŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥: {e}")
        print("\nè¯·ç¡®ä¿:")
        print("  1. åœ¨CosyVoiceç›®å½•ä¸‹è¿è¡Œ")
        print("  2. å·²å®‰è£…ä¾èµ–: pip install -r requirements.txt")
        print("  3. å·²æ·»åŠ è·¯å¾„: sys.path.append('third_party/Matcha-TTS')")
        return False


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='ä½¿ç”¨CosyVoice3æ‰¹é‡ç”Ÿæˆè®­ç»ƒéŸ³é¢‘')
    parser.add_argument('--script', default='training_script.json',
                       help='è®­ç»ƒæ–‡æ¡ˆJSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', default='digital_human_training_data',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--model', default='pretrained_models/Fun-CosyVoice3-0.5B',
                       help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--prompt', default='./asset/zero_shot_prompt.wav',
                       help='å‚è€ƒéŸ³é¢‘è·¯å¾„')
    parser.add_argument('--mode', default='instruct2', choices=['instruct2', 'zero_shot'],
                       help='ç”Ÿæˆæ¨¡å¼: instruct2(æ¨è) æˆ– zero_shot')
    parser.add_argument('--test', action='store_true',
                       help='æµ‹è¯•ç¯å¢ƒé…ç½®')

    args = parser.parse_args()

    # å¦‚æœæ˜¯æµ‹è¯•æ¨¡å¼
    if args.test:
        test_cosyvoice_setup()
        exit(0)

    # åˆ›å»ºç”Ÿæˆå™¨å¹¶è¿è¡Œ
    try:
        generator = CosyVoice3Generator(
            output_dir=args.output,
            model_dir=args.model,
            prompt_audio=args.prompt,
            mode=args.mode
        )

        metadata = generator.generate_training_set(script_json_path=args.script)

        print("\nğŸ“Š ç”Ÿæˆç»Ÿè®¡:")
        print(f"   æ€»å¥æ•°: {len(metadata)}")

        # æŒ‰sectionç»Ÿè®¡
        from collections import Counter
        sections = Counter([m['section'] for m in metadata])
        print(f"   Sectionæ•°: {len(sections)}")

        # æŒ‰æƒ…ç»ªç»Ÿè®¡
        emotions = Counter([m['emotion'] for m in metadata])
        print(f"\næŒ‰æƒ…ç»ªç»Ÿè®¡:")
        for emotion, count in emotions.items():
            print(f"   {emotion}: {count}å¥")

    except Exception as e:
        print(f"\nâŒ è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        print("\nè¯·è¿è¡Œæµ‹è¯•æ¨¡å¼æ£€æŸ¥ç¯å¢ƒ:")
        print("  python tts_batch_generator.py --test")
